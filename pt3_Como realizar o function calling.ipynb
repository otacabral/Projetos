{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3482e0b4",
   "metadata": {},
   "source": [
    "### 1.0) Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7fbbd",
   "metadata": {},
   "source": [
    "Aqui entramos em uma parta muito importante. Até então, tudo que fizemos foi nos conectar ao API do chat para que ele nos desse respostas de acordo com o que era perguntado. Bem, isso não muda muita coisa em relação ao que fazemos na própria interface do chat GPT caso nosso propósito fosse fazer perguntas e obter respostas.\n",
    "\n",
    "Portanto, iremos mostrar ao chat GPT que ele além de sua ferramenta incrível de geração de texto, também poderá acessar a base de dados ou funções que nós mesmo criarmos com informações específicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f19f7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.1) Function Callings (CHAMANDO FUNÇÕES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d023b",
   "metadata": {},
   "source": [
    "Para ensinar sobre, nada melhor do que um exemplo.\n",
    "\n",
    "O exemplo consiste no seguinte. Queremos que o chat nos diga informações sobre o tempo em determinadas regiões. Porém, ele só poderá acessar essas informações de uma função criada. Para facilitar nosso estudo, essa função terá apenas dois parâmetros sendo eles a localidade e unidade desejada. No entanto, em níveis mais avançados, podemos conectar a sites ou base de dados consolidadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa9bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas\n",
    "\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3499a",
   "metadata": {},
   "source": [
    "##### 1º) Definindo a nossa função que retorna a temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81539af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_temperatura_atual(local, unidade = 'celcius'):\n",
    "    if 'são paulo'in local.lower():\n",
    "        return json.dumps(\n",
    "            {'local':'São Paulo', 'temperatura': '32', 'unidade': unidade}\n",
    "        ) ### o comando \"json.dumps\" serve simplesmente para transformar esse dicionário em uma string. Até porque é uma llm.\n",
    "    elif \"porto alegre\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {'local': \"Porto Alegre\", 'temperatura':'25', 'unidade':unidade}\n",
    "        )\n",
    "    elif \"rio de janeiro\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {'local': \"Rio de Janeiro\", 'temperatura':'35', 'unidade':unidade}\n",
    "        )\n",
    "    else: ### esse else seria caso não fosse nenhum dos outros 3. Logo, daria uma resposta desconhecida\n",
    "        return json.dumps(\n",
    "            {'local': local, 'temperatura':'unknown'}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ae403",
   "metadata": {},
   "source": [
    "##### 2º) Como anexar a função à resposta do chat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6865d",
   "metadata": {},
   "source": [
    "Agora, quando formos rodar o código que o chat nos gera uma resposta, iremos colocar também o parâmetro \"tools\", que indica as ferramentas que ele pode ter acesso ao gerar a resposta. Irei colocar o código do tools, mas antes veja o código da resposta!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0874a2",
   "metadata": {},
   "source": [
    "A variável tools será uma lista de dicionários. Cada dicionário será uma tool específica (pode ter mais de uma). Nela, iremos especificar algumas coisas como o tipo de tool (no caso uma função que retorna a temperatura)\n",
    "\n",
    "a descrição que a tool possui, os parâmetros, o que faz etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb59554",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "    'type':'function',\n",
    "    'function':{\n",
    "        \"name\":'obter_temperatura_atual',\n",
    "        \"description\":\"Obtém a temperatura atual em um dada cidade\",\n",
    "        'parameters':{\n",
    "            'type':'object', ##sempre deixar type objects\n",
    "            'properties':{\n",
    "                'local':{\n",
    "                    'type':'string',\n",
    "                    'descripition': \"O nome da cidade. Ex: São Paulo\",\n",
    "                },\n",
    "                'unidade':{\n",
    "                    'type':'string',\n",
    "                    'enum': [\"celsius\", 'fahrenheit'] #limita as possibilidades para essas 2\n",
    "                }\n",
    "            },\n",
    "            \"required\":['local'] # indica quais parâmetros são necessários\n",
    "        }\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba39cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907b332d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obter_temperatura_atual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22976\\1544040762.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m funcoes_disponiveis = {\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;34m'obter_temperatura_atual'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobter_temperatura_atual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'obter_temperatura_atual' is not defined"
     ]
    }
   ],
   "source": [
    "####### CÓDIGO DA RESPOSTA\n",
    "\n",
    "### Caso o nosso tools tivesse mais de uma função, é comum criarmos o seguinte dicionário que correlaciona o nome da função com a própria função\n",
    "\n",
    "funcoes_disponiveis = {\n",
    "    'obter_temperatura_atual': obter_temperatura_atual\n",
    "}\n",
    "\n",
    "\n",
    "mensagens = [\n",
    "    {'role':'user', 'content':'Qual é a temperatura em São Paulo e Porto Alegre?'}\n",
    "]\n",
    "\n",
    "\n",
    "resposta = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-0125',\n",
    "    messages = mensagens,\n",
    "    tools = tools,\n",
    "    tool_choice = 'auto'\n",
    ") ## tool_choice é como o chat irá escolher essa ferramenta. Quando colocamos \"auto\" ele pode escolher de acordo como achar melhor. Mas podemos obriga-lo a escolher uma tool específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372e91a",
   "metadata": {},
   "source": [
    "Veja agora o que é a resposta dele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db95f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AtiDCqTd5hrZrDiXXsChPF9D0XogY', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xvzrpEG77oCvYnj0gll5AAGJ', function=Function(arguments='{\"local\": \"São Paulo\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function'), ChatCompletionMessageToolCall(id='call_AuI6e2THupTeBGFpiYQBTyeB', function=Function(arguments='{\"local\": \"Porto Alegre\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function')]))], created=1737841354, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=70, prompt_tokens=79, total_tokens=149, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta ### Repare que quando chegamos em \"content\" aparece None. E em \"tool_calls\" ele nos informa quais parâmetros devemos rodar na função para que ele obtenha a resposta desejada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c2574",
   "metadata": {},
   "source": [
    "Se você reparar, o atributo tool_calls é uma lista com 2 resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d559cd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessageToolCall(id='call_xvzrpEG77oCvYnj0gll5AAGJ', function=Function(arguments='{\"local\": \"São Paulo\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.choices[0].message.tool_calls[0] ### primeiro elemento da lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fc0187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessageToolCall(id='call_AuI6e2THupTeBGFpiYQBTyeB', function=Function(arguments='{\"local\": \"Porto Alegre\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.choices[0].message.tool_calls[1] ### segundo elemento da lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7e7aa",
   "metadata": {},
   "source": [
    "##### 3º) Como rodar a função e fornecer a resposta para o chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df227da2",
   "metadata": {},
   "source": [
    "Vamos recapitular um pouco o que foi feito até então. Nós fizemos uma pergunta ao chat referente a temperatura de dois lugares. E colocamos como parâmetro das respostas o tool. Esse tool serve para indicar que o API do chat GPT tem acesso a uma lista de ferramentas. No nosso caso essa lista tinha apenas uma função que chamamos de \"obter a temperatura atual\". Logo, quando rodamos a resposta, vimos acima que ele não gerou nenhum \"content\" como resposta. Ao invés disso, ele falou que a resposta se encontra ao rodar a função \"obter_temperatura_atual com os parâmetros específicos que ele mesmo recomendou.\n",
    "\n",
    "Logo, o que precisamos fazer nesse momento, é rodar as funções, obter a resposta e enviar para ele. Ok, mas como enviar para ele? Lembra lá no início do curso, aquela lista de mensagens registradas que colocávamos role = ['user' ou 'assistent']. Então, devemos registrar a resposta da função como \"role\":\"tool\". Isso é, ele vai entender que naquele histórico de conversa, em algum momento ele teve que rodar a função para o assistente gerar a resposta!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3503fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagem_resp = resposta.choices[0].message # isso representa a mensagem que o chat deu, leia em resposta\n",
    "tool_calls = mensagem_resp.tool_calls # representa a lista com as duas chamadas de função mostradas acima\n",
    "\n",
    "if tool_calls: ### isso serve para qualquer caso em que tool call não for NONE. Por que se for none, quer dizer que o chat não quer que chame as funções para obter as respostas.\n",
    "    mensagens.append(mensagem_resp) # colocando no registro de conversa do chat a informação da resposta que ele deu. Em sumo, 0 content e apenas a chamada das funçoes\n",
    "    for tool_call in tool_calls: # acessando cada um dos 2 tool_calls gerados\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = funcoes_disponiveis[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments) # o json.loads é uma forma de trasnformar o dicionário que estava escrito como string em apenas o dicionário. É o contrário do que foi feito la em cima com o json.dumps\n",
    "        function_response = function_to_call(local = function_args['local'], unidade = function_args['unidade']) # também pode usar o comando .get para selecionar a chave do dicionário; Ex: function_args.get('local')\n",
    "\n",
    "        mensagens.append(\n",
    "            {\n",
    "                'tool_call_id': tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "668dd477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Qual é a temperatura em São Paulo e Porto Alegre?'},\n",
       " ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FeduKsMJ28y6nCdyc8wKUXQw', function=Function(arguments='{\"local\": \"São Paulo\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function'), ChatCompletionMessageToolCall(id='call_5lVKjUe2s84dBH1wXAr6tk53', function=Function(arguments='{\"local\": \"Porto Alegre\", \"unidade\": \"celsius\"}', name='obter_temperatura_atual'), type='function')]),\n",
       " {'tool_call_id': 'call_FeduKsMJ28y6nCdyc8wKUXQw',\n",
       "  'role': 'tool',\n",
       "  'name': 'obter_temperatura_atual',\n",
       "  'content': '{\"local\": \"S\\\\u00e3o Paulo\", \"temperatura\": \"32\", \"unidade\": \"celsius\"}'},\n",
       " {'tool_call_id': 'call_5lVKjUe2s84dBH1wXAr6tk53',\n",
       "  'role': 'tool',\n",
       "  'name': 'obter_temperatura_atual',\n",
       "  'content': '{\"local\": \"Porto Alegre\", \"temperatura\": \"25\", \"unidade\": \"celsius\"}'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f08f61",
   "metadata": {},
   "source": [
    "##### 4º) Gerando a resposta final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b5e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta_final = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-0125',\n",
    "    messages = mensagens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e8a79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AtirMn9TxX0Ib10C4RNY9MV7d1mFt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A temperatura atual em São Paulo é de 32°C e em Porto Alegre é de 25°C.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737843844, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=155, total_tokens=179, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc06ce5",
   "metadata": {},
   "source": [
    "Repare agora que o \"content\" tem resultado. Vamos buscá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb48314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A temperatura atual em São Paulo é de 32°C e em Porto Alegre é de 25°C.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta_final.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
